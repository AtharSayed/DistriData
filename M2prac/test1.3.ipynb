{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders Columns: ['order_id', 'customer_id', 'order_status', 'order_amount']\n",
      "Customers Columns: ['1', 'Richard', 'Hernandez', 'XXXXXXXXX3', 'XXXXXXXXX4', '6303 Heather Plaza', 'Brownsville', 'TX', '78521']\n",
      "+-----------+--------+------------+------------+-------+---------+----------+----------+------------------+-----------+---+-----+\n",
      "|customer_id|order_id|order_status|order_amount|Richard|Hernandez|XXXXXXXXX3|XXXXXXXXX4|6303 Heather Plaza|Brownsville| TX|78521|\n",
      "+-----------+--------+------------+------------+-------+---------+----------+----------+------------------+-----------+---+-----+\n",
      "+-----------+--------+------------+------------+-------+---------+----------+----------+------------------+-----------+---+-----+\n",
      "\n",
      "+--------+-----------+------------+------------+-----------+-------+---------+----------+----------+------------------+-----------+---+-----+\n",
      "|order_id|customer_id|order_status|order_amount|customer_id|Richard|Hernandez|XXXXXXXXX3|XXXXXXXXX4|6303 Heather Plaza|Brownsville| TX|78521|\n",
      "+--------+-----------+------------+------------+-----------+-------+---------+----------+----------+------------------+-----------+---+-----+\n",
      "+--------+-----------+------------+------------+-----------+-------+---------+----------+----------+------------------+-----------+---+-----+\n",
      "\n",
      "\n",
      "ðŸ”¹ Join Strategy with Default Settings:\n",
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner, [customer_id])\n",
      ":- Relation [order_id#291,customer_id#292,order_status#293,order_amount#294] csv\n",
      "+- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "   +- Relation [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "customer_id: int, order_id: int, order_status: string, order_amount: double, Richard: string, Hernandez: string, XXXXXXXXX3: string, XXXXXXXXX4: string, 6303 Heather Plaza: string, Brownsville: string, TX: string, 78521: int\n",
      "Project [customer_id#292, order_id#291, order_status#293, order_amount#294, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "+- Join Inner, (customer_id#292 = customer_id#334)\n",
      "   :- Relation [order_id#291,customer_id#292,order_status#293,order_amount#294] csv\n",
      "   +- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "      +- Relation [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [customer_id#292, order_id#291, order_status#293, order_amount#294, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "+- Join Inner, (customer_id#292 = customer_id#334)\n",
      "   :- Filter isnotnull(customer_id#292)\n",
      "   :  +- Relation [order_id#291,customer_id#292,order_status#293,order_amount#294] csv\n",
      "   +- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "      +- Filter isnotnull(1#316)\n",
      "         +- Relation [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [customer_id#292, order_id#291, order_status#293, order_amount#294, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "   +- BroadcastHashJoin [customer_id#292], [customer_id#334], Inner, BuildRight, false\n",
      "      :- Filter isnotnull(customer_id#292)\n",
      "      :  +- FileScan csv [order_id#291,customer_id#292,order_status#293,order_amount#294] Batched: false, DataFilters: [isnotnull(customer_id#292)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/sayed/Desktop/DDP/prac3/data/orders_1gb.csv], PartitionFilters: [], PushedFilters: [IsNotNull(customer_id)], ReadSchema: struct<order_id:int,customer_id:int,order_status:string,order_amount:double>\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=316]\n",
      "         +- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "            +- Filter isnotnull(1#316)\n",
      "               +- FileScan csv [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] Batched: false, DataFilters: [isnotnull(1#316)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/sayed/Desktop/DDP/M2prac/data/part-00000 (1)], PartitionFilters: [], PushedFilters: [IsNotNull(1)], ReadSchema: struct<1:int,Richard:string,Hernandez:string,XXXXXXXXX3:string,XXXXXXXXX4:string,6303 Heather Pla...\n",
      "\n",
      "\n",
      "ðŸ”¹ Join Strategy After Disabling Broadcast:\n",
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner, [customer_id])\n",
      ":- Relation [order_id#291,customer_id#292,order_status#293,order_amount#294] csv\n",
      "+- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "   +- Relation [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "customer_id: int, order_id: int, order_status: string, order_amount: double, Richard: string, Hernandez: string, XXXXXXXXX3: string, XXXXXXXXX4: string, 6303 Heather Plaza: string, Brownsville: string, TX: string, 78521: int\n",
      "Project [customer_id#292, order_id#291, order_status#293, order_amount#294, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "+- Join Inner, (customer_id#292 = customer_id#334)\n",
      "   :- Relation [order_id#291,customer_id#292,order_status#293,order_amount#294] csv\n",
      "   +- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "      +- Relation [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [customer_id#292, order_id#291, order_status#293, order_amount#294, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "+- Join Inner, (customer_id#292 = customer_id#334)\n",
      "   :- Filter isnotnull(customer_id#292)\n",
      "   :  +- Relation [order_id#291,customer_id#292,order_status#293,order_amount#294] csv\n",
      "   +- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "      +- Filter isnotnull(1#316)\n",
      "         +- Relation [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [customer_id#292, order_id#291, order_status#293, order_amount#294, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "   +- SortMergeJoin [customer_id#292], [customer_id#334], Inner\n",
      "      :- Sort [customer_id#292 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(customer_id#292, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n",
      "      :     +- Filter isnotnull(customer_id#292)\n",
      "      :        +- FileScan csv [order_id#291,customer_id#292,order_status#293,order_amount#294] Batched: false, DataFilters: [isnotnull(customer_id#292)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/sayed/Desktop/DDP/prac3/data/orders_1gb.csv], PartitionFilters: [], PushedFilters: [IsNotNull(customer_id)], ReadSchema: struct<order_id:int,customer_id:int,order_status:string,order_amount:double>\n",
      "      +- Sort [customer_id#334 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(customer_id#334, 200), ENSURE_REQUIREMENTS, [plan_id=347]\n",
      "            +- Project [1#316 AS customer_id#334, Richard#317, Hernandez#318, XXXXXXXXX3#319, XXXXXXXXX4#320, 6303 Heather Plaza#321, Brownsville#322, TX#323, 78521#324]\n",
      "               +- Filter isnotnull(1#316)\n",
      "                  +- FileScan csv [1#316,Richard#317,Hernandez#318,XXXXXXXXX3#319,XXXXXXXXX4#320,6303 Heather Plaza#321,Brownsville#322,TX#323,78521#324] Batched: false, DataFilters: [isnotnull(1#316)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/sayed/Desktop/DDP/M2prac/data/part-00000 (1)], PartitionFilters: [], PushedFilters: [IsNotNull(1)], ReadSchema: struct<1:int,Richard:string,Hernandez:string,XXXXXXXXX3:string,XXXXXXXXX4:string,6303 Heather Pla...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "# âœ… Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Joins\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# âœ… Step 2: Define Schema for Orders Dataset\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"order_status\", StringType(), True),\n",
    "    StructField(\"order_amount\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# âœ… Step 3: Load Orders and Customers DataFrames\n",
    "orders_df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .schema(orders_schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(r\"C:\\Users\\sayed\\Desktop\\DDP\\prac3\\data\\orders_1gb.csv\")\n",
    "\n",
    "customers_df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(r\"C:\\Users\\sayed\\Desktop\\DDP\\M2prac\\data\\part-00000 (1)\")\n",
    "\n",
    "# âœ… Step 4: Print Column Names\n",
    "print(\"Orders Columns:\", orders_df.columns)\n",
    "print(\"Customers Columns:\", customers_df.columns)\n",
    "\n",
    "# âœ… Step 5: Rename Customer Column if Necessary\n",
    "if \"1\" in customers_df.columns:\n",
    "    customers_df = customers_df.withColumnRenamed(\"1\", \"customer_id\")\n",
    "\n",
    "# âœ… Step 6: Perform Inner Join (DataFrame API)\n",
    "inner_join_df = orders_df.join(customers_df, \"customer_id\", \"inner\")\n",
    "inner_join_df.show(5)\n",
    "\n",
    "# âœ… Step 7: Perform Inner Join (Spark SQL)\n",
    "orders_df.createOrReplaceTempView(\"orders\")\n",
    "customers_df.createOrReplaceTempView(\"customers\")\n",
    "\n",
    "inner_join_sql = spark.sql(\"\"\"\n",
    "    SELECT * FROM orders o\n",
    "    INNER JOIN customers c\n",
    "    ON o.customer_id = c.customer_id\n",
    "\"\"\")\n",
    "inner_join_sql.show(5)\n",
    "\n",
    "# âœ… Step 8: Check Join Strategy\n",
    "print(\"\\nðŸ”¹ Join Strategy with Default Settings:\")\n",
    "inner_join_df.explain(True)\n",
    "\n",
    "# âœ… Step 9: Disable Broadcast Join and Check Again\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")  # Disable Broadcast Join\n",
    "\n",
    "inner_join_df_no_broadcast = orders_df.join(customers_df, \"customer_id\", \"inner\")\n",
    "print(\"\\nðŸ”¹ Join Strategy After Disabling Broadcast:\")\n",
    "inner_join_df_no_broadcast.explain(True)\n",
    "\n",
    "# âœ… Step 10: Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
